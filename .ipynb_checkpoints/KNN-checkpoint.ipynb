{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "def file2matrix(filename):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "       导入训练数据\n",
    "    parameters:\n",
    "       filename: 数据文件路径\n",
    "    return:\n",
    "       数据矩阵 returnMat 和对应的类别\n",
    "    备注:前3个标签为属性值 后面一个标签为类别标签\n",
    "    \"\"\"\n",
    "    fr = open(filename)\n",
    "    numberOfLines = len(fr.readlines())\n",
    "    # 生成一个zero((2, 3))\n",
    "    returnMat = zeros((numberOfLines, 3))\n",
    "    classLabelVector = []\n",
    "    #fr = open(filename)\n",
    "    fr.close()\n",
    "    fr = open(filename)\n",
    "    index = 0\n",
    "    for line in fr.readlines():\n",
    "        line = line.strip()\n",
    "        listFromLine = line.split('\\t')\n",
    "        # 每列的属性数据\n",
    "        returnMat[index, :] = listFromLine[0:3]\n",
    "        # 每列的类别数据,就是label标签\n",
    "        classLabelVector.append(int(listFromLine[-1]))\n",
    "        index += 1\n",
    "    return returnMat, classLabelVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.0920000e+04 8.3269760e+00 9.5395200e-01]\n",
      " [1.4488000e+04 7.1534690e+00 1.6739040e+00]\n",
      " [2.6052000e+04 1.4418710e+00 8.0512400e-01]\n",
      " ...\n",
      " [2.6575000e+04 1.0650102e+01 8.6662700e-01]\n",
      " [4.8111000e+04 9.1345280e+00 7.2804500e-01]\n",
      " [4.3757000e+04 7.8826010e+00 1.3324460e+00]]\n"
     ]
    }
   ],
   "source": [
    "mat1, labelV = file2matrix(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\datingTestSet2.txt\")\n",
    "\n",
    "print (mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "datingDataMat, datingLabels = file2matrix(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\datingTestSet2.txt\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(datingDataMat[:, 0], datingDataMat[:, 1], 15.0*array(datingLabels), 15.0*array(datingLabels))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**归一化的定义**: 归一化就是要把需要处理的数据经过加工处理后 限制在你需要的一定范围内 首先归一化是为了后面的数据处理的方便 其次是保证程序运行时收敛加快 方法有如下:\n",
    "1. 线性函数转换 y = (x - MinValue)/(MaxValue - MinValue)\n",
    "2. 对数函数转换 y = log10(x) 以10为底数进行转换\n",
    "3. 反余切函数转换 y = arctan(x)*2/PI\n",
    "4. 式（1）将输入值换算为[-1,1]区间的值,在输出层用式2换算回初始值 归一化的具体作用是归纳 归一化在0-1之间的统计的概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoNorm(dataSet):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "      归一化特征值,消除特征之间量级不同导致的影响\n",
    "    parameter:\n",
    "      dataSet:数据集\n",
    "    return:\n",
    "    \n",
    "    归一化公式:\n",
    "      Y = (x - Xmin)/(Xmax - Xmin)\n",
    "      \n",
    "    \"\"\"\n",
    "    minVals = dataSet.min(0)\n",
    "    maxVals = dataSet.max(0)\n",
    "    \n",
    "    #极差\n",
    "    ranges = maxVals - minVals\n",
    "    normDataSet = zeros(shape(dataSet))\n",
    "    m = dataSet.shape[0]\n",
    "    normDataSet = dataSet - tile(minVals, (m, 1))\n",
    "    normDataSet = normDataSet/tile(ranges, (m, 1))\n",
    "    return normDataSet, ranges, minVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify0(inX, dataSet, labels, k):\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    # 距离度量 \n",
    "    diffMat = tile(inX, (dataSetSize, 1)) - dataSet\n",
    "    sqDiffMat = diffMat * 2\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    distances = sqDistances ** 0.5\n",
    "    \n",
    "    #将距离排序 从小到大\n",
    "    sortedDistIndicies = distance.argsort()\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        classCount[voteIlabel]  = classCount.get(voteIlabel, 0) + 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datingClassTest():\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "    parameters:\n",
    "    return:\n",
    "    \"\"\"\n",
    "    hoRatio = 0.1\n",
    "    datingDataMat, datingLabels = file2matrix(r\"r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\datingTestSet2.txt\")\n",
    "    # 归一化数据\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    m = normMat.shape[0]\n",
    "    numTestVecs = int(m * hoRatio)\n",
    "    print (\"numTestVecs=\", numTestVecs)\n",
    "    errorCount = 0.0\n",
    "    for i in range(numTestVecs):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
