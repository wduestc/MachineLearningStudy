{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result is: 1\n",
      "the result is :0\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "#------------ 项目案例1 屏蔽社区留言板的侮辱性言论 -----------\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "贝叶斯\n",
    "p(xy) = p(x|y)p(y)=p(y|x)p(x)\n",
    "\"\"\"\n",
    "\n",
    "def load_data_set():\n",
    "    \"\"\"\n",
    "    创建数据集\n",
    "    \"\"\"\n",
    "    posting_list = [\n",
    "        ['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "        ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "        ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "        ['stop', 'posting', 'stupid', 'worthless', 'gar e'],\n",
    "        ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "        ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']\n",
    "    ]\n",
    "    class_vec = [0, 1, 0, 1, 0, 1]\n",
    "    return posting_list, class_vec\n",
    "\n",
    "def create_vocab_list(dataset):\n",
    "    \"\"\"\n",
    "    获取所有单词的集合\n",
    "    :param data_set\n",
    "    :return\n",
    "    \"\"\"\n",
    "    vocab_set = set()\n",
    "    for item in dataset:\n",
    "        vocab_set = vocab_set | set(item)\n",
    "    return list(vocab_set)\n",
    "\n",
    "def set_of_words2vec(vocab_list, input_set):\n",
    "    \"\"\"\n",
    "    遍历查看该单词是否出现,出现该单词则将单词置为1\n",
    "    :param vocab_list: 所有单词集合列表\n",
    "    :param input_set:  输入数据集\n",
    "    :return: 匹配列表[0, 1, 0, 1...]\n",
    "    \"\"\"\n",
    "    result = [0] * len(vocab_list)\n",
    "    for word in input_set:\n",
    "        if word in vocab_list:\n",
    "            result[vocab_list.index(word)] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return result\n",
    "\n",
    "def _train_navie_bayes(train_mat, train_category):\n",
    "    \"\"\"\n",
    "    朴素贝叶斯分类原版\n",
    "    :param train_mat: type is ndarray\n",
    "    :param train_category: [0, 1, 0]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    train_doc_num = len(train_mat)\n",
    "    words_num = len(train_mat[0])\n",
    "    # 因为侮辱性的被标记为1\n",
    "    pos_abusive = np.sum(train_category)/train_doc_num\n",
    "    p0num = np.zeros(words_num)\n",
    "    p1num = np.zeros(words_num)\n",
    "    \n",
    "    #整个数据集单词出现的次数\n",
    "    p0num_all = 0\n",
    "    p1num_all = 0\n",
    "    \n",
    "    for i in range(train_doc_num):\n",
    "        # 遍历所有的文件\n",
    "        if train_category[i] == 1:\n",
    "            p1num += train_mat[i]\n",
    "            p1num_all += np.sum(train_mat[i])\n",
    "        else:\n",
    "            p0num += train_mat[i]\n",
    "            p0num_all += np.sum(train_mat[i])\n",
    "    # 后面需要改成取log函数\n",
    "    p1vec = p1num/p1num_all\n",
    "    p0vec = p0num/p0num_all\n",
    "    return p0vec, p1vec, pos_abusive\n",
    "\n",
    "def train_navie_bayes(train_mat, train_category):\n",
    "    \"\"\"\n",
    "    朴素贝叶斯分类修正版\n",
    "    :param train_mat: type is ndarray\n",
    "    :param train_category:\n",
    "    :return\n",
    "    \"\"\"\n",
    "    train_doc_num = len(train_mat)\n",
    "    words_num = len(train_mat[0])\n",
    "    \n",
    "    pos_abusive = np.sum(train_category)/train_doc_num\n",
    "    p0num = np.ones(words_num)\n",
    "    p1num = np.ones(words_num)\n",
    "    p0num_all = 2.0\n",
    "    p1num_all = 2.0\n",
    "    \n",
    "    for i in range(train_doc_num):\n",
    "        if train_category[i] == 1:\n",
    "            p1num += train_mat[i]\n",
    "            p1num_all += np.sum(train_mat[i])\n",
    "        else:\n",
    "            p0num += train_mat[i]\n",
    "            p0num_all += np.sum(train_mat[i])\n",
    "    # 取log函数\n",
    "    p1vec = np.log(p1num/p1num_all)\n",
    "    p0vec = np.log(p0num/p0num_all)\n",
    "    return p1vec, p0vec, pos_abusive\n",
    "\n",
    "def classify_naive_bayes(vec2classify, p0vec, p1vec, p_class1):\n",
    "    p1 = np.sum(vec2classify * p1vec) + np.log(p_class1)\n",
    "    p0 = np.sum(vec2classify * p0vec) + np.log(1 - p_class1)\n",
    "    if p1 > p0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def bag_words2vec(vocab_list, input_set):\n",
    "    result = [0] * len(vocab_list)\n",
    "    for word in input_set:\n",
    "        if word in vocab_list:\n",
    "            result[vocab_list.index(word)] += 1\n",
    "        else:\n",
    "            print('the word: {} is not in my vocabulary'.format(word))\n",
    "    return result\n",
    "\n",
    "def testing_naive_bayes():\n",
    "    #1. 加载数据集\n",
    "    list_post, list_classes = load_data_set()\n",
    "    #2. 创建单词集合\n",
    "    vocab_list = create_vocab_list(list_post)\n",
    "    #3.计算单词是否出现并创建数据矩阵\n",
    "    train_mat = []\n",
    "    for post_in in list_post:\n",
    "        train_mat.append(set_of_words2vec(vocab_list, post_in))\n",
    "    #4.训练数据\n",
    "    p0v, p1v, p_abusive = train_navie_bayes(np.array(train_mat), np.array(list_classes))\n",
    "    #5.测试数据\n",
    "    test_one = ['love', 'my', 'dalmation']\n",
    "    test_one_doc = np.array(set_of_words2vec(vocab_list, test_one))\n",
    "    print('the result is: {}'.format(classify_naive_bayes(test_one_doc, p0v, p1v, p_abusive)))\n",
    "    test_two = ['stupid', 'garbage']\n",
    "    test_two_doc = np.array(set_of_words2vec(vocab_list, test_two))\n",
    "    print('the result is :{}'.format(classify_naive_bayes(test_two_doc, p0v, p1v, p_abusive)))\n",
    "\n",
    "\n",
    "#testing_naive_bayes()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
