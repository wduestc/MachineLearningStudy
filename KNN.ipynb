{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "def file2matrix(filename):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "       导入训练数据\n",
    "    parameters:\n",
    "       filename: 数据文件路径\n",
    "    return:\n",
    "       数据矩阵 returnMat 和对应的类别\n",
    "    备注:前3个标签为属性值 后面一个标签为类别标签\n",
    "    \"\"\"\n",
    "    fr = open(filename)\n",
    "    numberOfLines = len(fr.readlines())\n",
    "    # 生成一个zero((2, 3))\n",
    "    returnMat = zeros((numberOfLines, 3))\n",
    "    classLabelVector = []\n",
    "    #fr = open(filename)\n",
    "    fr.close()\n",
    "    fr = open(filename)\n",
    "    index = 0\n",
    "    for line in fr.readlines():\n",
    "        line = line.strip()\n",
    "        listFromLine = line.split('\\t')\n",
    "        # 每列的属性数据\n",
    "        returnMat[index, :] = listFromLine[0:3]\n",
    "        # 每列的类别数据,就是label标签\n",
    "        classLabelVector.append(int(listFromLine[-1]))\n",
    "        index += 1\n",
    "    return returnMat, classLabelVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1 101]\n",
      " [  5  89]\n",
      " [108   5]\n",
      " [115   8]] ['love', 'love', 'action', 'action']\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "import numpy as np\n",
    "\n",
    "def createDataSet():\n",
    "    \"\"\"\n",
    "    desc:\n",
    "      创建数据集\n",
    "    parameters:\n",
    "      无\n",
    "    return:\n",
    "      group - 数据集\n",
    "      labels - 分类标签\n",
    "    \"\"\"\n",
    "    group = np.array([[1, 101], [5, 89], [108, 5], [115, 8]])\n",
    "    labels = ['love', 'love', 'action', 'action']\n",
    "    return group, labels\n",
    "\n",
    "group, labels = createDataSet()\n",
    "print (group, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['180601', '180602', '180603', '180604', '180605', '180606', '180607', '180608', '180609', '180610', '180611', '180612', '180613', '180614', '180615', '180616', '180617', '180618', '180619', '180620', '180621', '180622', '180623', '180624', '180625', '180626', '180627', '180628', '180629', '180630']\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import calendar\n",
    "\n",
    "def getMonthFirstDayAndLastDay(year=None, month=None, date_format='%Y-%m-%d'):\n",
    "    \"\"\"\n",
    "    desc:\n",
    "      获取某月的第一天和最后一天\n",
    "    parameters:\n",
    "      year - 年\n",
    "      month - 月\n",
    "      date_format - 转换的文件格式(默认%Y-%m-%d)\n",
    "    return:\n",
    "      firstDay, lastDay\n",
    "    \"\"\"\n",
    "    if year:\n",
    "        year = int(year)\n",
    "    else:\n",
    "        # 没有则获取当月的年\n",
    "        year = datetime.date.today().year\n",
    "    if month:\n",
    "        month = int(month)\n",
    "    else:\n",
    "        month = datetime.date.today().month\n",
    "    \n",
    "    firstDayWeekDay, monthRange = calendar.monthrange(year, month)\n",
    "    firstDay = datetime.date(year=year, month=month, day=1).strftime(date_format)\n",
    "    lastDay = datetime.date(year=year, month=month, day=monthRange).strftime(date_format)\n",
    "    return firstDay, lastDay\n",
    "    \n",
    "\n",
    "def getBetweenDays(begin_date, end_date, date_format):\n",
    "    \"\"\"\n",
    "    desc:\n",
    "     获取当月所有日期的列表\n",
    "    parameters:\n",
    "     begin_date -- 起始日期\n",
    "     end_date   -- 截止日期\n",
    "     date_format -- 时间格式\n",
    "    return:\n",
    "     返回指定日期范围的时间列表\n",
    "    \"\"\"\n",
    "    date_list = []\n",
    "    begin_date = datetime.datetime.strptime(begin_date, \"%Y-%m-%d\")\n",
    "    end_date = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    #begin_date = datetime.datetime.strptime(begin_date, \"%Y-%m-%d\")  \n",
    "    #end_date = datetime.datetime\n",
    "    #end_date = datetime.datetime.strptime(time.strftime('%Y-%m-%d',time.localtime(time.time())), \"%Y-%m-%d\")  \n",
    "    while begin_date <= end_date:  \n",
    "        date_str = begin_date.strftime(date_format)  \n",
    "        date_list.append(date_str)  \n",
    "        begin_date += datetime.timedelta(days=1)  \n",
    "    return date_list \n",
    "\n",
    "\n",
    "firstDay, lastDay = getMonthFirstDayAndLastDay(2018, 6, '%Y-%m-%d')\n",
    "print (getBetweenDays(firstDay, lastDay, \"%y%m%d\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.0920000e+04 8.3269760e+00 9.5395200e-01]\n",
      " [1.4488000e+04 7.1534690e+00 1.6739040e+00]\n",
      " [2.6052000e+04 1.4418710e+00 8.0512400e-01]\n",
      " ...\n",
      " [2.6575000e+04 1.0650102e+01 8.6662700e-01]\n",
      " [4.8111000e+04 9.1345280e+00 7.2804500e-01]\n",
      " [4.3757000e+04 7.8826010e+00 1.3324460e+00]]\n"
     ]
    }
   ],
   "source": [
    "mat1, labelV = file2matrix(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\datingTestSet2.txt\")\n",
    "\n",
    "print (mat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "datingDataMat, datingLabels = file2matrix(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\datingTestSet2.txt\")\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(datingDataMat[:, 0], datingDataMat[:, 1], 15.0*array(datingLabels), 15.0*array(datingLabels))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**归一化的定义**: 归一化就是要把需要处理的数据经过加工处理后 限制在你需要的一定范围内 首先归一化是为了后面的数据处理的方便 其次是保证程序运行时收敛加快 方法有如下:\n",
    "1. 线性函数转换 y = (x - MinValue)/(MaxValue - MinValue)\n",
    "2. 对数函数转换 y = log10(x) 以10为底数进行转换\n",
    "3. 反余切函数转换 y = arctan(x)*2/PI\n",
    "4. 式（1）将输入值换算为[-1,1]区间的值,在输出层用式2换算回初始值 归一化的具体作用是归纳 归一化在0-1之间的统计的概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoNorm(dataSet):\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "      归一化特征值,消除特征之间量级不同导致的影响\n",
    "    parameter:\n",
    "      dataSet:数据集\n",
    "    return:\n",
    "    \n",
    "    归一化公式:\n",
    "      Y = (x - Xmin)/(Xmax - Xmin)\n",
    "      \n",
    "    \"\"\"\n",
    "    minVals = dataSet.min(0)\n",
    "    maxVals = dataSet.max(0)\n",
    "    \n",
    "    #极差\n",
    "    ranges = maxVals - minVals\n",
    "    normDataSet = zeros(shape(dataSet))\n",
    "    m = dataSet.shape[0]\n",
    "    normDataSet = dataSet - tile(minVals, (m, 1))\n",
    "    normDataSet = normDataSet/tile(ranges, (m, 1))\n",
    "    return normDataSet, ranges, minVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action\n"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "import operator\n",
    "\n",
    "def classify0(inX, dataSet, labels, k):\n",
    "    \"\"\"\n",
    "    desc:\n",
    "      kNN算法\n",
    "    parameters:\n",
    "      inX - 用于分类的数据(测试集)\n",
    "      dataSet - 用于训练的数据(训练集)\n",
    "      labels - 分类标签\n",
    "      k - KNN算法参数\n",
    "    returns:\n",
    "      sortedClassCount[0][0] - 分类结果\n",
    "    \"\"\"\n",
    "    # 获取dataSet的行数\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    # 距离度量 \n",
    "    diffMat = tile(inX, (dataSetSize, 1)) - dataSet\n",
    "    # 二维特征相减后平凡\n",
    "    sqDiffMat = diffMat ** 2\n",
    "    # sum()所有元素相加 axis=0 列相加 axis=1 行相加\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    # 所有行相加 \n",
    "    distances = sqDistances ** 0.5\n",
    "    \n",
    "    #将距离排序 从小到大\n",
    "    sortedDistIndicies = distances.argsort()\n",
    "    #定义一个记录类别次数的字典\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        classCount[voteIlabel]  = classCount.get(voteIlabel, 0) + 1\n",
    "    #python3改成items()\n",
    "    #key=operator.itemgetter(1) 根据字典的值进行排序\n",
    "    #key=operator.itemgetter(0) 根据字典的键进行排序\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "group, labels = createDataSet()\n",
    "test = [101, 20]\n",
    "knn_class = classify0(test, group, labels, 3)\n",
    "print (knn_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:3\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:3\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:1\t 真实类别:1\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:3\t 真实类别:3\n",
      "分类结果:2\t 真实类别:2\n",
      "分类结果:2\t 真实类别:1\n",
      "分类结果:1\t 真实类别:1\n",
      "错误率:4.000000%\n"
     ]
    }
   ],
   "source": [
    "def datingClassTest():\n",
    "    \"\"\"\n",
    "    Desc:\n",
    "    parameters:\n",
    "    return:\n",
    "    \"\"\"\n",
    "    # 取所有数据的0.1\n",
    "    hoRatio = 0.1\n",
    "    \n",
    "    datingDataMat, datingLabels = file2matrix(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\datingTestSet2.txt\")\n",
    "    # 归一化数据 返回归一化后的矩阵 数据范围和数据最小值\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "                                              \n",
    "    m = normMat.shape[0]\n",
    "    numTestVecs = int(m * hoRatio)\n",
    "    #print (\"numTestVecs=\", numTestVecs)\n",
    "    errorCount = 0.0\n",
    "    for i in range(numTestVecs):\n",
    "       classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m, :], datingLabels[numTestVecs:m], 4)\n",
    "       print (\"分类结果:%d\\t 真实类别:%d\"%(classifierResult, datingLabels[i]))\n",
    "       if classifierResult != datingLabels[i]:\n",
    "          errorCount += 1.0\n",
    "    print (\"错误率:%f%%\"%((errorCount)/float(numTestVecs)*100))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    datingClassTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造一个能识别数字0-9的基于KNN分类器的手写数字识别系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    returnVect = zeros((1, 1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0, 32*i+j] = int(lineStr[j])\n",
    "    return returnVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "testVector = img2vector(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\trainingDigits\\0_13.txt\")\n",
    "print (testVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def handwritingClassTest():\n",
    "    hwLabels = []\n",
    "    traingFileList = listdir(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\trainingDigits\")\n",
    "    m = len(traingFileList)\n",
    "    traingMat = zero((m, 1024))\n",
    "    # hwLabels 存储0-9对应的index位置\n",
    "    for i in range(m):\n",
    "        fileNameStr = traingFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        hwLabels.append(classNumStr)\n",
    "        # 将32*32的矩阵->1*1024的矩阵\n",
    "        trainingMat[i, :] = img2vector(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\trainingDigits\\{}\".format(fileNameStr))\n",
    "    #导入测试数据\n",
    "    testFileList = listdir(r'C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\testDigits')\n",
    "    errorCount = 0.0\n",
    "    mTest = len(testFileList)\n",
    "    for i in range(mTest):\n",
    "          fileNameStr = testFileList[i]\n",
    "          fileStr = fileNameStr.split('.')[0]\n",
    "          classNumStr = int(fileStr.split('_')[0])\n",
    "          vectorUnderTest = img2vector(r'C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\testDigits\\%s'%fileNameStr)\n",
    "          classifierResult = classify0(vectorUndeTest, traingMat, hwLabels, 3)\n",
    "          print (\"the classifier came back with :%d, the real answer is: %d\"%(classiferResult, classNumStr))\n",
    "          if (classifierResult != classNumStr): errorCount += 1.0\n",
    "    print (\"\\nthe total number of errors is :%d\\n\"%errorCount)\n",
    "    print (\"\\nthe total error rate is :%f\\n\"%(errorCount/float(mTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "# 使用鸢尾花数据集进行测试\n",
    "from sklearn import neighbors\n",
    "from sklearn.datasets import load_iris\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "# 查看iris数据集\n",
    "iris = load_iris()\n",
    "#print (iris)\n",
    "mat1, labelV = file2matrix(r\"C:\\Users\\wd\\Documents\\GitHub\\MachineLearning\\input\\2.KNN\\datingTestSet2.txt\")\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "# 训练数据集\n",
    "knn.fit(mat1, labelV)\n",
    "#knn.fit(iris.data, iris.target)\n",
    "# 预测\n",
    "#predict = knn.predict([[0.1, 0.2, 0.3, 0.4]])\n",
    "# 阵列\n",
    "predict = knn.predict([[80920, 12.326976, 0.953952]])\n",
    "print (predict)\n",
    "#print (iris.target_names[predict])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
